{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HCL App Security\n",
    "Submitted by: </br>\n",
    "Akash Nagraj (01FB15ECS047) </br>\n",
    "Yash Mathur (01FB15ECS357)</br>\n",
    "Mukund Sood (01FB15ECS363)</br>\n",
    "Bishesh Sinha (01FB15ECS369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras Imports\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Conv1D, MaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sklearn Imports\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sklearn Imports\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GenSim Imports\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous Imports\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths to load:\n",
    "dataset_path = \"Processed.csv\"\n",
    "truth_value = \"expectedresults-1.2.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Vector dimensions\n",
    "vector_dimensions = 50\n",
    "\n",
    "# Word2Vec model Training Window\n",
    "window_size = 5\n",
    "\n",
    "# Number of workers used to create the Word2Vec model\n",
    "number_of_workers = 2\n",
    "\n",
    "# Minimum number of times a word must be present to be\n",
    "# included in the Word2Vec model\n",
    "min_word_count = 2\n",
    "\n",
    "# Specify name of the Word2Vec model to load\n",
    "# If no name is specified, a model is built\n",
    "Word2VecModelName = \"\"\n",
    "\n",
    "# Number of epochs for Neural Network Training\n",
    "training_epochs = 50\n",
    "\n",
    "# Training batch size\n",
    "training_batch_size  = 10\n",
    "\n",
    "# Toggle normalization of labels: 1 -> Enable; 0 -> Disable\n",
    "normalize_labels = 0\n",
    "\n",
    "# Set the word limit for each code\n",
    "max_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Convert `raw_code` to a list of words:\n",
    "'''\n",
    "def code_to_wordlist(raw_code):\n",
    "    '''\n",
    "    The code block is converted to a list of words\n",
    "    '''\n",
    "\n",
    "    # Removing punctuation\n",
    "    # table = string.maketrans('''!()-[]{};:'\"\\,<>./?@#$%^&*_~''')\n",
    "    # raw_code.translate(table, string.punctuation)\n",
    "\n",
    "    # Removing all numbers\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_code)\n",
    "\n",
    "    # Converting all letters to lowercase\n",
    "    words = letters_only.lower().strip().split()\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Convert `code` into lines\n",
    "'''\n",
    "def code_to_lines(code, tokenizer, remove_stopwords = False):\n",
    "    '''\n",
    "    The code is tokenized to form a list of sentences\n",
    "    '''\n",
    "    # Splitting each code block into lines\n",
    "    raw_code = tokenizer.tokenize(code.strip())\n",
    "\n",
    "    # Loop over each line of code\n",
    "    lines = []\n",
    "    for line in raw_code:\n",
    "\n",
    "        # If a line of code is empty, skip it\n",
    "        if(len(line) > 0):\n",
    "            lines.append(code_to_wordlist(line))\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to create word vectors\n",
    "'''\n",
    "def makeFeatureVectors(line, model, num_features):\n",
    "    '''\n",
    "    Create a word vectors of the words passed using the Word2Vec Model\n",
    "    '''\n",
    "    # Initial word vector to a zero vector\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "\n",
    "    # Initialize Number of Words to 0\n",
    "    nwords = 0\n",
    "    \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set to improve speed\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "\n",
    "    for word in line:\n",
    "        if word in index2word_set:\n",
    "            # Count the number of words\n",
    "            nwords = nwords + 1\n",
    "            # Create a vector by adding all word vectors it contains\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    \n",
    "    # Divide feature vector by 0 to get average word vector\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to create word vectors from a set of answers\n",
    "'''\n",
    "def getAvgFeatureVecs(code, model, num_features):\n",
    "    '''\n",
    "    Given a set of answers, calculate the average feature \n",
    "    vector and return a 2D numpy array for each one \n",
    "    '''\n",
    "    # Initialize a counter\n",
    "    counter = 0\n",
    "\n",
    "    # Allocate a 2D numpy array, for speed\n",
    "    codeFeatureVecs = np.zeros((len(code),num_features),dtype=\"float32\")\n",
    "    \n",
    "    # Loop through the answers in an answer set\n",
    "    for line in code:\n",
    "\n",
    "       # Print a status message every 1000th answer\n",
    "       if (counter%1000 == 0):\n",
    "           print(\"CodeBlock %d of %d processed.\" % (counter, len(code)))\n",
    "       \n",
    "       # Get average feature vector for each answer in answer set\n",
    "       codeFeatureVecs[counter] = makeFeatureVectors(line, model, num_features)\n",
    "       \n",
    "       # Increment the counter\n",
    "       counter = counter + 1\n",
    "        \n",
    "    return codeFeatureVecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_labels (row):\n",
    "        if row[\" real vulnerability\"] == True:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "#     if row[\"Abbrev.\"] == \"XSS\":\n",
    "#         return 1\n",
    "#     elif row[\"Abbrev.\"] == \"SECXSS2\":\n",
    "#         return 1\n",
    "#     elif row[\"Abbrev.\"] == \"SECCI\" :\n",
    "#         return 2\n",
    "#     elif row[\"Abbrev.\"] == \"SECSQLIJDBC\":\n",
    "#         return 3\n",
    "#     elif row[\"Abbrev.\"] == \"SECSQLISPRJDBC\":\n",
    "#         return 3\n",
    "#     else: \n",
    "#         return 0\n",
    "#     return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_category (row):\n",
    "    if row[\"Abbrev.\"] == \"XSS\":\n",
    "        return \"xss\"\n",
    "    elif row[\"Abbrev.\"] == \"SECXSS2\":\n",
    "        return \"xss\"\n",
    "    elif row[\"Abbrev.\"] == \"SECCI\" :\n",
    "        return \"cmdi\"\n",
    "    elif row[\"Abbrev.\"] == \"SECSQLIJDBC\":\n",
    "        return \"sqli\"\n",
    "    elif row[\"Abbrev.\"] == \"SECSQLISPRJDBC\":\n",
    "        return \"sqli\"\n",
    "    elif row[\"Abbrev.\"] == \"SECCU\":\n",
    "        return \"securecookie\"\n",
    "    elif row[\"Abbrev.\"] == \"SECHOC\":\n",
    "        return \"securecookie\"\n",
    "    elif row[\"Abbrev.\"] == \"SECPR\":\n",
    "        return \"weakrand\"\n",
    "    elif row[\"Abbrev.\"] == \"SECTBV\":\n",
    "        return \"trustbound\"\n",
    "    elif row[\"Abbrev.\"] == \"SECXPI\":\n",
    "        return \"xpathi\"\n",
    "    elif row[\"Abbrev.\"] == \"SECSHA1\":\n",
    "        return \"hash\"\n",
    "    elif row[\"Abbrev.\"] == \"SECPTI\":\n",
    "        return \"pathtraver\"\n",
    "    elif row[\"Abbrev.\"] == \"SECMD5\":\n",
    "        return \"hash\"\n",
    "    elif row[\"Abbrev.\"] == \"HRS\":\n",
    "        return \"securecookie\"\n",
    "    elif row[\"Abbrev.\"] == \"SECIC\":\n",
    "        return \"securecookie\"\n",
    "    elif row[\"Abbrev.\"] == \"SECLDAPI\":\n",
    "        return \"ldapi\"\n",
    "    elif row[\"Abbrev.\"] == \"SECDU\":\n",
    "        return \"crypto\"\n",
    "    elif row[\"Abbrev.\"] == \"CIPINT\":\n",
    "        return \"hash\" \n",
    "    elif row[\"Abbrev.\"] == \"SECPTO\":\n",
    "        return \"pathtraver\"\n",
    "    elif row[\"Abbrev.\"] == \"PT\":\n",
    "        return \"pathtraver\"\n",
    "    elif row[\"Abbrev.\"] == \"STAIV\":\n",
    "        return \"crypto\"\n",
    "    elif row[\"Abbrev.\"] == \"PADORA\":\n",
    "        return \"crypto\"\n",
    "    elif row[\"Abbrev.\"] == \"SECSH\":\n",
    "        return \"xss\"\n",
    "    elif row[\"Abbrev.\"] == \"PADORA\":\n",
    "        return \"crypto\"\n",
    "    elif row[\"Abbrev.\"] == \"SECSP\":\n",
    "        return \"xss\"\n",
    "    elif row[\"Abbrev.\"] == \"SECSSQ\":\n",
    "        return \"xss\"\n",
    "    elif row[\"Abbrev.\"] == \"SECSP\":\n",
    "        return \"xss\"\n",
    "    elif row[\"Abbrev.\"] == \"SECHRS\":\n",
    "        return \"xss\"\n",
    "    elif row[\"Abbrev.\"] == \"SECSP\":\n",
    "        return \"xss\"\n",
    "    elif row[\"Abbrev.\"] == \"SECSHR\":\n",
    "        return \"xss\"\n",
    "    elif row[\"Abbrev.\"] == \"SQL\":\n",
    "        return \"sqli\"\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the pre-computed vectors for the suspect lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>category</th>\n",
       "      <th>real vulnerability</th>\n",
       "      <th>cwe</th>\n",
       "      <th>Benchmark version: 1.2</th>\n",
       "      <th>2016-06-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BenchmarkTest00001</td>\n",
       "      <td>pathtraver</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BenchmarkTest00002</td>\n",
       "      <td>pathtraver</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BenchmarkTest00003</td>\n",
       "      <td>hash</td>\n",
       "      <td>True</td>\n",
       "      <td>328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BenchmarkTest00004</td>\n",
       "      <td>trustbound</td>\n",
       "      <td>True</td>\n",
       "      <td>501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BenchmarkTest00005</td>\n",
       "      <td>crypto</td>\n",
       "      <td>True</td>\n",
       "      <td>327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename    category   real vulnerability   cwe  \\\n",
       "0  BenchmarkTest00001  pathtraver                 True    22   \n",
       "1  BenchmarkTest00002  pathtraver                 True    22   \n",
       "2  BenchmarkTest00003        hash                 True   328   \n",
       "3  BenchmarkTest00004  trustbound                 True   501   \n",
       "4  BenchmarkTest00005      crypto                 True   327   \n",
       "\n",
       "    Benchmark version: 1.2   2016-06-1  \n",
       "0                      NaN         NaN  \n",
       "1                      NaN         NaN  \n",
       "2                      NaN         NaN  \n",
       "3                      NaN         NaN  \n",
       "4                      NaN         NaN  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_values = pd.read_csv(truth_value, header = 0, delimiter = \",\")\n",
    "truth_values.rename(columns={'# test name': 'Filename',' category': 'category'}, inplace=True)\n",
    "truth_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = []\n",
    "lines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Abbrev.</th>\n",
       "      <th>Type</th>\n",
       "      <th>Lineno.</th>\n",
       "      <th>CodeBlock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BenchmarkTest01910</td>\n",
       "      <td>SECPR</td>\n",
       "      <td>PREDICTABLE_RANDOM</td>\n",
       "      <td>['53']</td>\n",
       "      <td>['double value = java.lang.Math.random();']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BenchmarkTest00577</td>\n",
       "      <td>SECCU</td>\n",
       "      <td>COOKIE_USAGE</td>\n",
       "      <td>['91', '92', '113', '114']</td>\n",
       "      <td>['if (cookieName.equals(cookie.getName())) {',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BenchmarkTest00958</td>\n",
       "      <td>SECHOC</td>\n",
       "      <td>HTTPONLY_COOKIE</td>\n",
       "      <td>['36']</td>\n",
       "      <td>['javax.servlet.http.Cookie userCookie = new j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BenchmarkTest00124</td>\n",
       "      <td>SECSH</td>\n",
       "      <td>SERVLET_HEADER</td>\n",
       "      <td>['44', '45']</td>\n",
       "      <td>['if (request.getHeader(\"BenchmarkTest00124\") ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BenchmarkTest00507</td>\n",
       "      <td>SECXSS2</td>\n",
       "      <td>XSS_SERVLET</td>\n",
       "      <td>['92', '93', '94']</td>\n",
       "      <td>['response.getWriter().println(', 'user + \" ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename  Abbrev.                Type  \\\n",
       "0  BenchmarkTest01910    SECPR  PREDICTABLE_RANDOM   \n",
       "1  BenchmarkTest00577    SECCU        COOKIE_USAGE   \n",
       "2  BenchmarkTest00958   SECHOC     HTTPONLY_COOKIE   \n",
       "3  BenchmarkTest00124    SECSH      SERVLET_HEADER   \n",
       "4  BenchmarkTest00507  SECXSS2         XSS_SERVLET   \n",
       "\n",
       "                      Lineno.  \\\n",
       "0                      ['53']   \n",
       "1  ['91', '92', '113', '114']   \n",
       "2                      ['36']   \n",
       "3                ['44', '45']   \n",
       "4          ['92', '93', '94']   \n",
       "\n",
       "                                           CodeBlock  \n",
       "0        ['double value = java.lang.Math.random();']  \n",
       "1  ['if (cookieName.equals(cookie.getName())) {',...  \n",
       "2  ['javax.servlet.http.Cookie userCookie = new j...  \n",
       "3  ['if (request.getHeader(\"BenchmarkTest00124\") ...  \n",
       "4  ['response.getWriter().println(', 'user + \" ha...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_headings = [\"Filename\", \"Abbrev.\", \"Type\", \"Lineno.\", \"CodeBlock\"]\n",
    "dataset = pd.read_csv(dataset_path, header = 0, delimiter = \",\", names = column_headings)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the corresponding labels. The classes are defined as\n",
    "0 - No Vulnerability <br>\n",
    "1 - XSS <br>\n",
    "2 - CLI <br>\n",
    "3 - SLI <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Abbrev.</th>\n",
       "      <th>Type</th>\n",
       "      <th>Lineno.</th>\n",
       "      <th>CodeBlock</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BenchmarkTest01910</td>\n",
       "      <td>SECPR</td>\n",
       "      <td>PREDICTABLE_RANDOM</td>\n",
       "      <td>['53']</td>\n",
       "      <td>['double value = java.lang.Math.random();']</td>\n",
       "      <td>weakrand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BenchmarkTest00577</td>\n",
       "      <td>SECCU</td>\n",
       "      <td>COOKIE_USAGE</td>\n",
       "      <td>['91', '92', '113', '114']</td>\n",
       "      <td>['if (cookieName.equals(cookie.getName())) {',...</td>\n",
       "      <td>securecookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BenchmarkTest00958</td>\n",
       "      <td>SECHOC</td>\n",
       "      <td>HTTPONLY_COOKIE</td>\n",
       "      <td>['36']</td>\n",
       "      <td>['javax.servlet.http.Cookie userCookie = new j...</td>\n",
       "      <td>securecookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BenchmarkTest00124</td>\n",
       "      <td>SECSH</td>\n",
       "      <td>SERVLET_HEADER</td>\n",
       "      <td>['44', '45']</td>\n",
       "      <td>['if (request.getHeader(\"BenchmarkTest00124\") ...</td>\n",
       "      <td>xss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BenchmarkTest00507</td>\n",
       "      <td>SECXSS2</td>\n",
       "      <td>XSS_SERVLET</td>\n",
       "      <td>['92', '93', '94']</td>\n",
       "      <td>['response.getWriter().println(', 'user + \" ha...</td>\n",
       "      <td>xss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename  Abbrev.                Type  \\\n",
       "0  BenchmarkTest01910    SECPR  PREDICTABLE_RANDOM   \n",
       "1  BenchmarkTest00577    SECCU        COOKIE_USAGE   \n",
       "2  BenchmarkTest00958   SECHOC     HTTPONLY_COOKIE   \n",
       "3  BenchmarkTest00124    SECSH      SERVLET_HEADER   \n",
       "4  BenchmarkTest00507  SECXSS2         XSS_SERVLET   \n",
       "\n",
       "                      Lineno.  \\\n",
       "0                      ['53']   \n",
       "1  ['91', '92', '113', '114']   \n",
       "2                      ['36']   \n",
       "3                ['44', '45']   \n",
       "4          ['92', '93', '94']   \n",
       "\n",
       "                                           CodeBlock      category  \n",
       "0        ['double value = java.lang.Math.random();']      weakrand  \n",
       "1  ['if (cookieName.equals(cookie.getName())) {',...  securecookie  \n",
       "2  ['javax.servlet.http.Cookie userCookie = new j...  securecookie  \n",
       "3  ['if (request.getHeader(\"BenchmarkTest00124\") ...           xss  \n",
       "4  ['response.getWriter().println(', 'user + \" ha...           xss  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['category'] = dataset.apply(lambda row: gen_category(row),axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Abbrev.</th>\n",
       "      <th>Type</th>\n",
       "      <th>Lineno.</th>\n",
       "      <th>CodeBlock</th>\n",
       "      <th>category</th>\n",
       "      <th>real vulnerability</th>\n",
       "      <th>cwe</th>\n",
       "      <th>Benchmark version: 1.2</th>\n",
       "      <th>2016-06-1</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BenchmarkTest01910</td>\n",
       "      <td>SECPR</td>\n",
       "      <td>PREDICTABLE_RANDOM</td>\n",
       "      <td>['53']</td>\n",
       "      <td>['double value = java.lang.Math.random();']</td>\n",
       "      <td>weakrand</td>\n",
       "      <td>True</td>\n",
       "      <td>330</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BenchmarkTest00577</td>\n",
       "      <td>SECCU</td>\n",
       "      <td>COOKIE_USAGE</td>\n",
       "      <td>['91', '92', '113', '114']</td>\n",
       "      <td>['if (cookieName.equals(cookie.getName())) {',...</td>\n",
       "      <td>securecookie</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BenchmarkTest00958</td>\n",
       "      <td>SECHOC</td>\n",
       "      <td>HTTPONLY_COOKIE</td>\n",
       "      <td>['36']</td>\n",
       "      <td>['javax.servlet.http.Cookie userCookie = new j...</td>\n",
       "      <td>securecookie</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BenchmarkTest00124</td>\n",
       "      <td>SECSH</td>\n",
       "      <td>SERVLET_HEADER</td>\n",
       "      <td>['44', '45']</td>\n",
       "      <td>['if (request.getHeader(\"BenchmarkTest00124\") ...</td>\n",
       "      <td>xss</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BenchmarkTest00507</td>\n",
       "      <td>SECXSS2</td>\n",
       "      <td>XSS_SERVLET</td>\n",
       "      <td>['92', '93', '94']</td>\n",
       "      <td>['response.getWriter().println(', 'user + \" ha...</td>\n",
       "      <td>xss</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename  Abbrev.                Type  \\\n",
       "0  BenchmarkTest01910    SECPR  PREDICTABLE_RANDOM   \n",
       "1  BenchmarkTest00577    SECCU        COOKIE_USAGE   \n",
       "2  BenchmarkTest00958   SECHOC     HTTPONLY_COOKIE   \n",
       "3  BenchmarkTest00124    SECSH      SERVLET_HEADER   \n",
       "4  BenchmarkTest00507  SECXSS2         XSS_SERVLET   \n",
       "\n",
       "                      Lineno.  \\\n",
       "0                      ['53']   \n",
       "1  ['91', '92', '113', '114']   \n",
       "2                      ['36']   \n",
       "3                ['44', '45']   \n",
       "4          ['92', '93', '94']   \n",
       "\n",
       "                                           CodeBlock      category  \\\n",
       "0        ['double value = java.lang.Math.random();']      weakrand   \n",
       "1  ['if (cookieName.equals(cookie.getName())) {',...  securecookie   \n",
       "2  ['javax.servlet.http.Cookie userCookie = new j...  securecookie   \n",
       "3  ['if (request.getHeader(\"BenchmarkTest00124\") ...           xss   \n",
       "4  ['response.getWriter().println(', 'user + \" ha...           xss   \n",
       "\n",
       "   real vulnerability    cwe  Benchmark version: 1.2  2016-06-1  labels  \n",
       "0                True    330                   False      False       1  \n",
       "1               False  False                   False      False       0  \n",
       "2               False  False                   False      False       0  \n",
       "3               False  False                   False      False       0  \n",
       "4               False  False                   False      False       0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.merge(dataset, truth_values, how='left')\n",
    "temp_df.fillna(\"False\", inplace=True)\n",
    "temp_df['labels'] = temp_df.apply(lambda row: gen_labels(row),axis=1)\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "#Loading keras tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(temp_df[\"CodeBlock\"])\n",
    "word_index = t.word_index\n",
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code_block_in_consideration in temp_df[\"CodeBlock\"]:\n",
    "    # Append the lines of code\n",
    "    lines += code_to_lines(code_block_in_consideration, tokenizer, True)\n",
    "    # Append the code blocks\n",
    "    code.append(code_block_in_consideration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a Word2Vec Model name is specified\n",
    "if(Word2VecModelName):\n",
    "    # Load a locally saved model\n",
    "    v2wmodel = Word2Vec.load(Word2VecModelName)\n",
    "else:\n",
    "    # Building the Word2Vec Model with the specified parameters\n",
    "    v2wmodel = word2vec.Word2Vec(lines, size=vector_dimensions, window=window_size, min_count=min_word_count, workers=number_of_workers)\n",
    "    # Save Word2Vec model with specified Name\n",
    "    v2wmodel.save(\"Word2VecModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeBlock 0 of 6845 processed.\n",
      "CodeBlock 1000 of 6845 processed.\n",
      "CodeBlock 2000 of 6845 processed.\n",
      "CodeBlock 3000 of 6845 processed."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CodeBlock 4000 of 6845 processed.\n",
      "CodeBlock 5000 of 6845 processed.\n",
      "CodeBlock 6000 of 6845 processed.\n"
     ]
    }
   ],
   "source": [
    "blockTrainVectors = getAvgFeatureVecs(code, v2wmodel, vector_dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Dataset into Train set and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(blockTrainVectors, temp_df[\"labels\"], test_size=0.20, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_clf = svm.SVC(decision_function_shape='ovo')\n",
    "svm_clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.44%\n"
     ]
    }
   ],
   "source": [
    "predicted_svm_clf = svm_clf.predict(X_test)\n",
    "accuracy_svm_clf = accuracy_score(y_test, predicted_svm_clf)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_svm_clf * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (One Vs Rest Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_svm_clf = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.10%\n"
     ]
    }
   ],
   "source": [
    "predicted_lin_svm_clf = lin_svm_clf.predict(X_test)\n",
    "accuracy_lin_svm_clf = accuracy_score(y_test, predicted_lin_svm_clf)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_lin_svm_clf * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forrest_clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "random_forrest_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.81%\n"
     ]
    }
   ],
   "source": [
    "random_forest_pred = random_forrest_clf.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, random_forest_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = XGBClassifier(max_depth=7, learning_rate=0.2, n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgboost_model.fit(X_train, y_train, verbose=True)\n",
    "# make predictions for test data\n",
    "y_pred = xgboost_model.predict(X_test)\n",
    "xgboost_predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.88%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, xgboost_predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf1 = VotingClassifier(estimators=[('xg', xgboost_model), ('rf', random_forrest_clf)], voting='hard')\n",
    "eclf1 = eclf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "ensemble_pred = eclf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.45%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, ensemble_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = blockTrainVectors.shape[1] \n",
    "embedding_dim = 128\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 512\n",
    "drop = 0.5\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv1d_6: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-249-5bb5108277d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    520\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    521\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    472\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv1d_6: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=50, activation='relu'))\n",
    "model.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('weights.{epoch:03d}-{val_acc:.4f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5476 samples, validate on 1369 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[6,31] = -1 is not in [0, 2035)\n\t [[Node: embedding_17/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/embedding_17/GatherV2_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_17/embeddings/read, embedding_17/Cast, embedding_17/GatherV2/axis)]]\n\nCaused by op 'embedding_17/GatherV2', defined at:\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-224-eedee6635398>\", line 2, in <module>\n    embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=sequence_length)(inputs)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 1215, in gather\n    return tf.gather(reference, indices)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 2736, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3065, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[6,31] = -1 is not in [0, 2035)\n\t [[Node: embedding_17/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/embedding_17/GatherV2_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_17/embeddings/read, embedding_17/Cast, embedding_17/GatherV2/axis)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[6,31] = -1 is not in [0, 2035)\n\t [[Node: embedding_17/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/embedding_17/GatherV2_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_17/embeddings/read, embedding_17/Cast, embedding_17/GatherV2/axis)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-226-381d90149d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# starts training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[6,31] = -1 is not in [0, 2035)\n\t [[Node: embedding_17/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/embedding_17/GatherV2_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_17/embeddings/read, embedding_17/Cast, embedding_17/GatherV2/axis)]]\n\nCaused by op 'embedding_17/GatherV2', defined at:\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-224-eedee6635398>\", line 2, in <module>\n    embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=sequence_length)(inputs)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 1215, in gather\n    return tf.gather(reference, indices)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 2736, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3065, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/mathuryash5/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[6,31] = -1 is not in [0, 2035)\n\t [[Node: embedding_17/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/embedding_17/GatherV2_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_17/embeddings/read, embedding_17/Cast, embedding_17/GatherV2/axis)]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, callbacks=[checkpoint], validation_data=(X_test, y_test))  # starts training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
